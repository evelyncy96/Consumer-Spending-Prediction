{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Spending Predictive\n",
    "\n",
    "- **Goal:** Predict the amount of purchase for consumers\n",
    "- **Data source:** please refer to the dataset in the repository\n",
    "- **Model:** Ensemble Stacking/ Deep Neural Network/ Support Vector Regressor/ ElasticNet/ Regression Tree/ KNN Regressor\n",
    "\n",
    "### Process\n",
    "\n",
    "- Data Preprocessing\n",
    "- Modeling (Including Hyperparameter tuning)\n",
    "- Conclusion",
    "Reference: GitHub user bgg11117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, auc, confusion_matrix, \n",
    "                            plot_confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>source_r</th>\n",
       "      <th>source_s</th>\n",
       "      <th>source_t</th>\n",
       "      <th>source_u</th>\n",
       "      <th>source_p</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>3662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>2900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3883</td>\n",
       "      <td>3914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   US  source_a  source_c  source_b  source_d  source_e  source_m  source_o  \\\n",
       "0   1         0         0         1         0         0         0         0   \n",
       "1   1         0         0         0         0         1         0         0   \n",
       "2   1         0         0         0         0         0         0         0   \n",
       "\n",
       "   source_h  source_r  source_s  source_t  source_u  source_p  source_x  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         1         0         0         0   \n",
       "\n",
       "   source_w  Freq  last_update_days_ago  1st_update_days_ago  Web order  \\\n",
       "0         0     2                  3662                 3662          1   \n",
       "1         0     0                  2900                 2900          1   \n",
       "2         0     2                  3883                 3914          0   \n",
       "\n",
       "   Gender=male  Address_is_res  Spending  \n",
       "0            0               1    127.87  \n",
       "1            1               0      0.00  \n",
       "2            0               0    127.48  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HW3.csv').drop(['sequence_number','Purchase'], axis= 1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the int data into float data\n",
    "column1 = df.loc[:, df.columns.isin(['Freq', 'last_update_days_ago', '1st_update_days_ago','Spending'])].columns\n",
    "for col in column1:\n",
    "    df[col] = df[col].astype('float')\n",
    "\n",
    "# Change the dummy variable into string data type\n",
    "column2 = df.loc[:, ~df.columns.isin(['Freq', 'last_update_days_ago', '1st_update_days_ago','Spending'])].columns\n",
    "for col in column2:\n",
    "    df[col] = df[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US                      0\n",
       "source_a                0\n",
       "source_c                0\n",
       "source_b                0\n",
       "source_d                0\n",
       "source_e                0\n",
       "source_m                0\n",
       "source_o                0\n",
       "source_h                0\n",
       "source_r                0\n",
       "source_s                0\n",
       "source_t                0\n",
       "source_u                0\n",
       "source_p                0\n",
       "source_x                0\n",
       "source_w                0\n",
       "Freq                    0\n",
       "last_update_days_ago    0\n",
       "1st_update_days_ago     0\n",
       "Web order               0\n",
       "Gender=male             0\n",
       "Address_is_res          0\n",
       "Spending                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X = df.iloc[:,:22]\n",
    "y = df.iloc[:,22]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "# Define cross-validation set\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(estimator, param_grid, cv=inner_cv, scoring='neg_mean_squared_error'):\n",
    "\n",
    "    # Create pipeline to standardize features and perform gridsearch\n",
    "    scaler = ColumnTransformer(\n",
    "                transformers=[('ss', StandardScaler(), [\"Freq\", \"last_update_days_ago\", \"1st_update_days_ago\"])],\n",
    "                remainder=\"passthrough\")\n",
    "                # set remainder=\"passthrough\" so that the non-specified columns will not be dropped  \n",
    "\n",
    "    pipe = Pipeline([('scaler', scaler), ('estimator', estimator)])\n",
    "\n",
    "    clf = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=-1, cv=inner_cv, scoring=scoring, error_score = 'raise')\n",
    "    grid_result = clf.fit(X_train, y_train)\n",
    "    \n",
    "    # best params of gridsearch \n",
    "    print(f\"Best score is {grid_result.best_score_} with best param {grid_result.best_params_}\")\n",
    "\n",
    "    # prediction result\n",
    "    y_pred = clf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Prediction result -> MSE = {mse}\") \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create param_grid for all the hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression(resularization: ElasticNet) hyperparameter\n",
    "elasticnet_paramGrid = dict(estimator__l1_ratio = [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "# KNN hyperparamter\n",
    "k = list(range(2,15))\n",
    "knn_paramGrid = dict(estimator__n_neighbors = k)\n",
    "\n",
    "# Regression Tree hyperparamter\n",
    "depth = list(range(2,6))\n",
    "dtr_paramGrid = dict(estimator__max_depth = depth)\n",
    "\n",
    "# SVR hyperparamter\n",
    "svr_paramGrid = dict(estimator__kernel = ['rbf'], estimator__gamma = [1e-3, 1e-4], estimator__C = [1, 10, 100, 1000])\n",
    "\n",
    "# Neural Network\n",
    "activations = ['relu', 'tanh']\n",
    "optimizers = ['adam']\n",
    "hiddens = [64, 128, 256]\n",
    "epochs = list(range(3, 10))\n",
    "nn_paramGrid = dict(estimator__activation=activations, \n",
    "                     estimator__optimizer=optimizers, \n",
    "                     estimator__hidden=hiddens, \n",
    "                     estimator__epochs = epochs)\n",
    "\n",
    "# Ensemble method hyperparameter\n",
    "stack_paramGrid = {'estimator__regrtree__max_depth': depth}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (resularization: ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -16763.62882315244 with best param {'estimator__l1_ratio': 0.9}\n",
      "Prediction result -> MSE = 17757.601219225937\n"
     ]
    }
   ],
   "source": [
    "elasticnet_paramGrid = dict(estimator__l1_ratio = [0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "EN = ElasticNet()\n",
    "gridsearch(EN, elasticnet_paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -17521.96483054584 with best param {'estimator__n_neighbors': 10}\n",
      "Prediction result -> MSE = 19217.8189857825\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor() \n",
    "gridsearch(knn, knn_paramGrid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -18544.884478096414 with best param {'estimator__max_depth': 3}\n",
      "Prediction result -> MSE = 19685.53248668529\n"
     ]
    }
   ],
   "source": [
    "regr_tree = DecisionTreeRegressor()\n",
    "gridsearch(regr_tree, dtr_paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -18798.134845108973 with best param {'estimator__C': 1000, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}\n",
      "Prediction result -> MSE = 20488.117916344934\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR()\n",
    "gridsearch(svr_rbf, svr_paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_construct(activation, optimizer, hidden):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden, input_dim=X_train.shape[1], activation=activation))\n",
    "    model.add(Dense(hidden, activation=activation))\n",
    "    model.add(Dense(hidden, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-224-bd47c6744bfa>:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  NN = KerasRegressor(build_fn = nn_construct, verbose = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -15418.869329424706 with best param {'estimator__activation': 'relu', 'estimator__epochs': 9, 'estimator__hidden': 256, 'estimator__optimizer': 'adam'}\n",
      "Prediction result -> MSE = 15866.246731986128\n"
     ]
    }
   ],
   "source": [
    "# Since Neural Network only accept float data, I then transform the object data into float data\n",
    "\n",
    "df_nn = df.copy()\n",
    "for col in column2:\n",
    "    df_nn[col] = df_nn[col].astype('float')\n",
    "\n",
    "# Train-Test Split\n",
    "X = df_nn.iloc[:,:22]\n",
    "y = df_nn.iloc[:,22]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "NN = KerasRegressor(build_fn = nn_construct, verbose = 0)\n",
    "\n",
    "gridsearch(NN, nn_paramGrid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is -17385.47402379638 with best param {'estimator__regrtree__max_depth': 5}\n",
      "Prediction result -> MSE = 17618.37960483427\n"
     ]
    }
   ],
   "source": [
    "for col in column2:\n",
    "    df[col] = df[col].astype('str')\n",
    "\n",
    "# Train-Test Split\n",
    "X = df.iloc[:,:22]\n",
    "y = df.iloc[:,22]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "stacking_estimators = [('regrtree', DecisionTreeRegressor()),\n",
    "              ('elasticnet', ElasticNet(random_state=42, l1_ratio= 0.9)),\n",
    "              ('knnreg', KNeighborsRegressor(n_neighbors= 10)),\n",
    "              ('svr',SVR(C = 1000, gamma = 0.001, kernel = 'rbf'))]\n",
    "               \n",
    "ensemble_stacking = StackingRegressor(estimators= stacking_estimators, final_estimator=RandomForestRegressor())\n",
    "\n",
    "gridsearch(ensemble_stacking, stack_paramGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I first created a function to compiled the normalization and gridsearch into pipeline. The return of the function including the best gridsearch score, best parameter of the model, and the MSE of test set of each model. The result shows that Deep Neural Network is the best model with the lowest MSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
